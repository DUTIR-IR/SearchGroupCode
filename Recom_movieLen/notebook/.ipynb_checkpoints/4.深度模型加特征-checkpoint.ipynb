{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:15.766317Z",
     "start_time": "2020-10-13T15:34:15.103402Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:15.772351Z",
     "start_time": "2020-10-13T15:34:15.768216Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:16.092686Z",
     "start_time": "2020-10-13T15:34:15.774197Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:16.334362Z",
     "start_time": "2020-10-13T15:34:16.094677Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:16.348373Z",
     "start_time": "2020-10-13T15:34:16.336152Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda:0'\n",
    "else:\n",
    "    DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:16.396037Z",
     "start_time": "2020-10-13T15:34:16.350011Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle('../data/processed/data_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:16.413369Z",
     "start_time": "2020-10-13T15:34:16.397771Z"
    }
   },
   "outputs": [],
   "source": [
    "total_usr = len(set(data_df.usr_id.tolist()))\n",
    "total_item = len(set(data_df.item_id.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:16.430366Z",
     "start_time": "2020-10-13T15:34:16.416037Z"
    }
   },
   "outputs": [],
   "source": [
    "usr_feature_df = pd.read_pickle('../data/processed/usr_feature_df.pkl')\n",
    "item_feature_df = pd.read_pickle('../data/processed/item_feature_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:16.435412Z",
     "start_time": "2020-10-13T15:34:16.432000Z"
    }
   },
   "outputs": [],
   "source": [
    "u_feature_dim = usr_feature_df['features'][0].shape[0]\n",
    "i_feature_dim = item_feature_df['features'][0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取特征辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:16.446145Z",
     "start_time": "2020-10-13T15:34:16.436960Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_UI_feature(uid,iid,\n",
    "           usr_feautre_df=usr_feature_df,\n",
    "           item_feature_df=item_feature_df):\n",
    "    '''给定用户和物品id进行特征查找 此处id是处理后的id即-1后的id\n",
    "    '''\n",
    "    \n",
    "    u_feature = usr_feature_df.loc[uid,'features']\n",
    "\n",
    "    u_feature = np.array(u_feature)\n",
    "\n",
    "    i_feature = item_feature_df.loc[iid,'features']\n",
    "\n",
    "    i_feature = np.array(i_feature)\n",
    "\n",
    "    return u_feature,i_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.深度模型 修改加入特征处理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:16.464303Z",
     "start_time": "2020-10-13T15:34:16.447839Z"
    }
   },
   "outputs": [],
   "source": [
    "class RecManModel(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 usr_num:int,\n",
    "                 item_num:int,\n",
    "                 emb_usr_size:int,\n",
    "                 emb_item_size:int,\n",
    "                 usr_feature_dim:int,\n",
    "                 item_feature_dim:int,\n",
    "                 feature_hidden_size:int,\n",
    "                 interact_hidden_size:int):\n",
    "        '''\n",
    "        usr_num 和 item_num 为对应用户和物品的总数\n",
    "        emb_size设定用户和物品的隐变量维度\n",
    "        feature_dim 为对应用户和物品的特征维度 处理后拼接\n",
    "        feature_hidden_size 为输入特征映射的维度\n",
    "        interact_hidden_size 为原来交互时特征维度\n",
    "        '''\n",
    "        super(RecManModel,self).__init__()\n",
    "        self.usr_num = usr_num\n",
    "        self.item_num = item_num\n",
    "        self.emb_usr_size = emb_usr_size\n",
    "        self.emb_item_size = emb_item_size\n",
    "        self.usr_feature_dim = usr_feature_dim\n",
    "        self.item_feature_dim = item_feature_dim\n",
    "        self.feature_hidden_size = feature_hidden_size\n",
    "        self.interact_hidden_size = interact_hidden_size\n",
    "        \n",
    "        # 查看显卡设备是否可用 \n",
    "        if torch.cuda.is_available():\n",
    "            self.device = 'cuda:0'\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "            \n",
    "        self.UserEmbeddingLayer = torch.nn.Embedding(num_embeddings=self.usr_num,\n",
    "                                                     embedding_dim=self.emb_usr_size)\n",
    "        self.ItemEmbeddingLayer = torch.nn.Embedding(num_embeddings=self.item_num,\n",
    "                                                     embedding_dim=self.emb_item_size)\n",
    "        \n",
    "        self.UserFeatureLayer = torch.nn.Linear(in_features=self.emb_usr_size,\n",
    "                                                out_features=self.interact_hidden_size)\n",
    "        self.ItemFeatureLayer = torch.nn.Linear(in_features=self.emb_item_size,\n",
    "                                               out_features=self.interact_hidden_size)\n",
    "        \n",
    "        self.UserMannualFeatureLayer = torch.nn.Linear(in_features=self.usr_feature_dim,\n",
    "                                                       out_features=self.feature_hidden_size)\n",
    "        self.ItemMannualFeatureLayer = torch.nn.Linear(in_features=self.item_feature_dim,\n",
    "                                                       out_features=self.feature_hidden_size)\n",
    "        \n",
    "        \n",
    "        # to device\n",
    "        self.UserEmbeddingLayer.to(self.device)\n",
    "        self.UserFeatureLayer.to(self.device)\n",
    "        self.ItemEmbeddingLayer.to(self.device)\n",
    "        self.ItemFeatureLayer.to(self.device)\n",
    "        self.UserMannualFeatureLayer.to(self.device)\n",
    "        self.ItemMannualFeatureLayer.to(self.device)\n",
    "        \n",
    "        \n",
    "    def forward(self,uid_batch,iid_batch,u_man_feature_batch,i_man_feature_batch):\n",
    "        '''输入一个batch的usr和item进行交互\n",
    "        '''\n",
    "        if not torch.is_tensor(uid_batch):\n",
    "            u_batch_tensor = torch.tensor(uid_batch)\n",
    "        else:\n",
    "            u_batch_tensor = uid_batch\n",
    "        if not torch.is_tensor(iid_batch):\n",
    "            i_batch_tensor = torch.tensor(iid_batch)\n",
    "        else:\n",
    "            i_batch_tensor = iid_batch\n",
    "        \n",
    "        if not torch.is_tensor(u_man_feature_batch):\n",
    "            u_man_feature_batch = torch.tensor(u_man_feature_batch)\n",
    "        if not torch.is_tensor(i_man_feature_batch):\n",
    "            i_man_feature_batch = torch.tensor(i_man_feature_batch)\n",
    "        \n",
    "        # 装入设备\n",
    "        u_batch_tensor = u_batch_tensor.to(self.device)\n",
    "        i_batch_tensor = i_batch_tensor.to(self.device)\n",
    "        u_man_feature_batch = u_man_feature_batch.to(self.device)\n",
    "        i_man_feature_batch = i_man_feature_batch.to(self.device)\n",
    "        \n",
    "        # 数据类型转换\n",
    "        u_man_feature_batch = u_man_feature_batch.to(torch.float)\n",
    "        i_man_feature_batch = i_man_feature_batch.to(torch.float)\n",
    "        \n",
    "        # 嵌入 向量化\n",
    "        \n",
    "        u_emb_tensor = self.UserEmbeddingLayer(u_batch_tensor)\n",
    "        i_emb_tensor = self.ItemEmbeddingLayer(i_batch_tensor)\n",
    "        \n",
    "        # 特征抽取 和 非线性化\n",
    "        u_feature = self.UserFeatureLayer(u_emb_tensor)\n",
    "        i_feature = self.ItemFeatureLayer(i_emb_tensor)\n",
    "        \n",
    "        u_feature = torch.relu(u_feature)\n",
    "        i_feature = torch.relu(i_feature)\n",
    "        \n",
    "        # 外部特征映射\n",
    "        \n",
    "        u_mannual_feature = self.UserMannualFeatureLayer(u_man_feature_batch)\n",
    "        i_mannual_feature = self.ItemMannualFeatureLayer(i_man_feature_batch)\n",
    "        \n",
    "        u_mannual_feature = torch.relu(u_mannual_feature)\n",
    "        i_mannual_feature = torch.relu(i_mannual_feature)\n",
    "        \n",
    "        # 隐式显式特征拼接\n",
    "        u_final_feature = torch.cat([u_feature,u_mannual_feature],dim=1)\n",
    "        i_final_feature = torch.cat([i_feature,i_mannual_feature],dim=1)\n",
    "        \n",
    "        batch_size = u_feature.shape[0]\n",
    "        interact_hidden_size = self.feature_hidden_size + self.interact_hidden_size\n",
    "        u_final_feature = u_final_feature.reshape(batch_size,1,interact_hidden_size)\n",
    "        i_final_feature = i_final_feature.reshape(batch_size,interact_hidden_size,1)\n",
    "        \n",
    "        output = torch.bmm(u_final_feature,i_final_feature)\n",
    "        output = torch.squeeze(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:19.119184Z",
     "start_time": "2020-10-13T15:34:16.465839Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn = RecManModel(usr_num=total_usr,item_num=total_item,\n",
    "                 emb_usr_size=50,emb_item_size=150,\n",
    "                 usr_feature_dim=u_feature_dim,item_feature_dim=i_feature_dim,\n",
    "                 feature_hidden_size=10,interact_hidden_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:19.152934Z",
     "start_time": "2020-10-13T15:34:19.122587Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = data_df.sample(n=32)\n",
    "\n",
    "usr_batch = [int(i) for i in sample.usr_id.tolist()]\n",
    "item_batch = [int(i) for i in sample.item_id.tolist()]\n",
    "sample =sample.reset_index(drop=True)\n",
    "\n",
    "usr_feature,item_feature = [],[]\n",
    "for num,i in enumerate(sample.itertuples()):\n",
    "    \n",
    "    usr_id = int(sample.loc[num,'usr_id'])-1\n",
    "    item_id = int(sample.loc[num,'item_id'])-1\n",
    "    u,i = get_UI_feature(usr_id,item_id)\n",
    "    usr_feature.append(u)\n",
    "    item_feature.append(i)\n",
    "usr_feature = np.stack(usr_feature)\n",
    "item_feature = np.stack(item_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:19.206593Z",
     "start_time": "2020-10-13T15:34:19.154867Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6906, 2.4191, 0.8169, 1.6972, 1.1681, 3.0045, 2.5780, 2.0790, 1.3601,\n",
       "        0.4192, 1.9775, 1.6817, 3.8452, 1.9936, 1.0571, 1.5272, 0.8252, 2.3773,\n",
       "        1.6979, 2.1573, 1.8671, 4.0534, 1.7376, 0.5534, 0.3037, 2.3241, 1.1503,\n",
       "        0.7811, 3.0241, 1.0510, 0.7794, 0.5163], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn(usr_batch,item_batch,usr_feature,item_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:19.217831Z",
     "start_time": "2020-10-13T15:34:19.208646Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLManDataSet(Dataset):\n",
    "    def __init__(self,df,usr_feature_df=usr_feature_df,item_feature_df=item_feature_df):\n",
    "        '''\n",
    "        输入df 构造dataset\n",
    "        输出 样本编号和标注\n",
    "        '''\n",
    "        self.df = df.copy()\n",
    "        # 注意 原始数据用户id和物品id从1开始的，但是在embedding过程中是从0算的，因此此处减一\n",
    "        self.df['usr_id'] = df['usr_id'].apply(lambda x:int(x)-1)\n",
    "        self.df['item_id'] = df['item_id'].apply(lambda x:int(x)-1)\n",
    "        self.df['rating'] = df['rating'].apply(lambda x:int(x))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample_df = self.df.iloc[idx]\n",
    "        usr_feature,item_feature = get_UI_feature(sample_df.usr_id,sample_df.item_id)\n",
    "        sample = (sample_df.usr_id,sample_df.item_id,usr_feature,item_feature,sample_df.rating)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:19.503657Z",
     "start_time": "2020-10-13T15:34:19.219797Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_df_lst = []\n",
    "for i in range(5):\n",
    "    df_fname = '../data/processed/cv_{0}_df.pkl'.format(i+1)\n",
    "    df = pd.read_pickle(df_fname)\n",
    "    cv_df_lst.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型、优化器、损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:19.513376Z",
     "start_time": "2020-10-13T15:34:19.505584Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = RecManModel(usr_num=total_usr,item_num=total_item,\n",
    "                 emb_usr_size=50,emb_item_size=150,\n",
    "                 usr_feature_dim=u_feature_dim,item_feature_dim=i_feature_dim,\n",
    "                 feature_hidden_size=10,interact_hidden_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:19.521454Z",
     "start_time": "2020-10-13T15:34:19.514890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecManModel(\n",
       "  (UserEmbeddingLayer): Embedding(943, 50)\n",
       "  (ItemEmbeddingLayer): Embedding(1682, 150)\n",
       "  (UserFeatureLayer): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (ItemFeatureLayer): Linear(in_features=150, out_features=25, bias=True)\n",
       "  (UserMannualFeatureLayer): Linear(in_features=3, out_features=10, bias=True)\n",
       "  (ItemMannualFeatureLayer): Linear(in_features=20, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:19.531871Z",
     "start_time": "2020-10-13T15:34:19.523060Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([\n",
    "        {'params': model.parameters()},\n",
    "                ], lr=0.005,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:34:19.542456Z",
     "start_time": "2020-10-13T15:34:19.533472Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练测试过程\n",
    "\n",
    "仅训练一个step的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T15:37:54.132973Z",
     "start_time": "2020-10-13T15:34:19.544220Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Test on cv_1_df\n",
      "Starting training porcess...\n",
      "Batch:0 Loss:5.99376106262207\n",
      "Batch:1 Loss:6.159246921539307\n",
      "Batch:2 Loss:6.090018272399902\n",
      "Batch:3 Loss:6.892715930938721\n",
      "Batch:4 Loss:4.588624954223633\n",
      "Batch:5 Loss:5.650768756866455\n",
      "Batch:6 Loss:4.795273303985596\n",
      "Batch:7 Loss:5.318187713623047\n",
      "Batch:8 Loss:4.009875297546387\n",
      "Batch:9 Loss:3.886538505554199\n",
      "Batch:10 Loss:3.368165969848633\n",
      "Batch:11 Loss:2.714223861694336\n",
      "Batch:12 Loss:2.88714861869812\n",
      "Batch:13 Loss:2.632943868637085\n",
      "Batch:14 Loss:2.704464912414551\n",
      "Batch:15 Loss:3.0262200832366943\n",
      "Batch:16 Loss:3.131519317626953\n",
      "Batch:17 Loss:4.6460771560668945\n",
      "Batch:18 Loss:3.559967041015625\n",
      "Batch:19 Loss:3.6407463550567627\n",
      "Batch:20 Loss:3.476149082183838\n",
      "Batch:21 Loss:3.1928277015686035\n",
      "Batch:22 Loss:2.7037534713745117\n",
      "Batch:23 Loss:2.392691135406494\n",
      "Batch:24 Loss:2.4546163082122803\n",
      "Batch:25 Loss:2.0850327014923096\n",
      "Batch:26 Loss:2.214890718460083\n",
      "Batch:27 Loss:2.2167513370513916\n",
      "Batch:28 Loss:2.7848289012908936\n",
      "Batch:29 Loss:2.94637393951416\n",
      "Batch:30 Loss:2.2013041973114014\n",
      "Batch:31 Loss:2.5995869636535645\n",
      "Batch:32 Loss:1.9352505207061768\n",
      "Batch:33 Loss:1.9945290088653564\n",
      "Batch:34 Loss:2.2080936431884766\n",
      "Batch:35 Loss:1.8943837881088257\n",
      "Batch:36 Loss:1.9697420597076416\n",
      "Batch:37 Loss:2.3889708518981934\n",
      "Batch:38 Loss:1.9751360416412354\n",
      "Batch:39 Loss:1.9048562049865723\n",
      "Batch:40 Loss:2.0847644805908203\n",
      "Batch:41 Loss:1.862860083580017\n",
      "Batch:42 Loss:1.7471449375152588\n",
      "Batch:43 Loss:1.935023307800293\n",
      "Batch:44 Loss:1.6784154176712036\n",
      "Batch:45 Loss:1.6821115016937256\n",
      "Batch:46 Loss:1.954278826713562\n",
      "Batch:47 Loss:1.646499514579773\n",
      "Batch:48 Loss:1.4211077690124512\n",
      "Batch:49 Loss:1.7075655460357666\n",
      "Batch:50 Loss:1.6092042922973633\n",
      "Batch:51 Loss:1.644838571548462\n",
      "Batch:52 Loss:1.4981439113616943\n",
      "Batch:53 Loss:1.7037763595581055\n",
      "Batch:54 Loss:1.8353456258773804\n",
      "Batch:55 Loss:1.4909706115722656\n",
      "Batch:56 Loss:1.6575320959091187\n",
      "Batch:57 Loss:1.5214133262634277\n",
      "Batch:58 Loss:1.5314432382583618\n",
      "Batch:59 Loss:1.5935344696044922\n",
      "Batch:60 Loss:1.6092331409454346\n",
      "Batch:61 Loss:1.400181531906128\n",
      "Batch:62 Loss:1.4373157024383545\n",
      "Batch:63 Loss:1.4820971488952637\n",
      "Batch:64 Loss:1.3914072513580322\n",
      "Batch:65 Loss:1.5178205966949463\n",
      "Batch:66 Loss:1.2723186016082764\n",
      "Batch:67 Loss:1.5036653280258179\n",
      "Batch:68 Loss:1.3402109146118164\n",
      "Batch:69 Loss:1.4945995807647705\n",
      "Batch:70 Loss:1.192615032196045\n",
      "Batch:71 Loss:1.4690786600112915\n",
      "Batch:72 Loss:1.5028759241104126\n",
      "Batch:73 Loss:1.3821271657943726\n",
      "Batch:74 Loss:1.4981379508972168\n",
      "Batch:75 Loss:1.4637458324432373\n",
      "Batch:76 Loss:1.2386384010314941\n",
      "Batch:77 Loss:1.3582801818847656\n",
      "Batch:78 Loss:1.6899104118347168\n",
      "MSE on cv_1_df:1.2853207268953464\n",
      "----------------\n",
      "Test on cv_2_df\n",
      "Starting training porcess...\n",
      "Batch:0 Loss:1.5328166484832764\n",
      "Batch:1 Loss:1.6220201253890991\n",
      "Batch:2 Loss:1.4242565631866455\n",
      "Batch:3 Loss:1.2636216878890991\n",
      "Batch:4 Loss:1.2432794570922852\n",
      "Batch:5 Loss:1.5291119813919067\n",
      "Batch:6 Loss:1.444151520729065\n",
      "Batch:7 Loss:2.0530943870544434\n",
      "Batch:8 Loss:1.2942885160446167\n",
      "Batch:9 Loss:1.5655932426452637\n",
      "Batch:10 Loss:1.4686455726623535\n",
      "Batch:11 Loss:1.3215711116790771\n",
      "Batch:12 Loss:1.4140082597732544\n",
      "Batch:13 Loss:1.1899909973144531\n",
      "Batch:14 Loss:1.2465126514434814\n",
      "Batch:15 Loss:1.2632091045379639\n",
      "Batch:16 Loss:1.3691686391830444\n",
      "Batch:17 Loss:1.3644158840179443\n",
      "Batch:18 Loss:1.3581523895263672\n",
      "Batch:19 Loss:1.2345174551010132\n",
      "Batch:20 Loss:1.1437841653823853\n",
      "Batch:21 Loss:1.3790435791015625\n",
      "Batch:22 Loss:1.2772623300552368\n",
      "Batch:23 Loss:1.1155667304992676\n",
      "Batch:24 Loss:1.2853434085845947\n",
      "Batch:25 Loss:1.2246248722076416\n",
      "Batch:26 Loss:1.2339637279510498\n",
      "Batch:27 Loss:1.0805423259735107\n",
      "Batch:28 Loss:1.2383010387420654\n",
      "Batch:29 Loss:1.0981419086456299\n",
      "Batch:30 Loss:1.222029685974121\n",
      "Batch:31 Loss:1.4708478450775146\n",
      "Batch:32 Loss:1.1950252056121826\n",
      "Batch:33 Loss:1.0286595821380615\n",
      "Batch:34 Loss:1.1908695697784424\n",
      "Batch:35 Loss:1.0806009769439697\n",
      "Batch:36 Loss:1.1679039001464844\n",
      "Batch:37 Loss:1.2257252931594849\n",
      "Batch:38 Loss:1.1224950551986694\n",
      "Batch:39 Loss:1.200556993484497\n",
      "Batch:40 Loss:1.2918665409088135\n",
      "Batch:41 Loss:1.1834874153137207\n",
      "Batch:42 Loss:1.1288795471191406\n",
      "Batch:43 Loss:1.18220853805542\n",
      "Batch:44 Loss:1.204182744026184\n",
      "Batch:45 Loss:1.0503456592559814\n",
      "Batch:46 Loss:1.2795052528381348\n",
      "Batch:47 Loss:1.081817626953125\n",
      "Batch:48 Loss:0.941818118095398\n",
      "Batch:49 Loss:1.2151670455932617\n",
      "Batch:50 Loss:1.1569024324417114\n",
      "Batch:51 Loss:1.2961033582687378\n",
      "Batch:52 Loss:1.019141674041748\n",
      "Batch:53 Loss:1.2007622718811035\n",
      "Batch:54 Loss:1.2651543617248535\n",
      "Batch:55 Loss:1.0868226289749146\n",
      "Batch:56 Loss:1.0892300605773926\n",
      "Batch:57 Loss:1.1446701288223267\n",
      "Batch:58 Loss:1.1575554609298706\n",
      "Batch:59 Loss:1.2339228391647339\n",
      "Batch:60 Loss:1.2197060585021973\n",
      "Batch:61 Loss:1.1097877025604248\n",
      "Batch:62 Loss:1.1977583169937134\n",
      "Batch:63 Loss:1.1921693086624146\n",
      "Batch:64 Loss:1.0268385410308838\n",
      "Batch:65 Loss:1.236427903175354\n",
      "Batch:66 Loss:0.9730264544487\n",
      "Batch:67 Loss:1.2008997201919556\n",
      "Batch:68 Loss:1.1127991676330566\n",
      "Batch:69 Loss:1.2014824151992798\n",
      "Batch:70 Loss:0.9363563656806946\n",
      "Batch:71 Loss:1.1834663152694702\n",
      "Batch:72 Loss:1.1604880094528198\n",
      "Batch:73 Loss:1.200033187866211\n",
      "Batch:74 Loss:1.214187741279602\n",
      "Batch:75 Loss:1.1397892236709595\n",
      "Batch:76 Loss:0.9861103892326355\n",
      "Batch:77 Loss:1.15374755859375\n",
      "Batch:78 Loss:1.210299015045166\n",
      "MSE on cv_2_df:1.107250534363659\n",
      "----------------\n",
      "Test on cv_3_df\n",
      "Starting training porcess...\n",
      "Batch:0 Loss:1.298514485359192\n",
      "Batch:1 Loss:1.3561382293701172\n",
      "Batch:2 Loss:1.1873750686645508\n",
      "Batch:3 Loss:1.0390100479125977\n",
      "Batch:4 Loss:1.026412010192871\n",
      "Batch:5 Loss:1.2964133024215698\n",
      "Batch:6 Loss:1.238224983215332\n",
      "Batch:7 Loss:1.5104366540908813\n",
      "Batch:8 Loss:1.098251461982727\n",
      "Batch:9 Loss:1.3329026699066162\n",
      "Batch:10 Loss:1.185477614402771\n",
      "Batch:11 Loss:1.176971435546875\n",
      "Batch:12 Loss:1.2229443788528442\n",
      "Batch:13 Loss:1.0365220308303833\n",
      "Batch:14 Loss:1.0711419582366943\n",
      "Batch:15 Loss:1.0766634941101074\n",
      "Batch:16 Loss:1.1672182083129883\n",
      "Batch:17 Loss:1.1908472776412964\n",
      "Batch:18 Loss:1.2404851913452148\n",
      "Batch:19 Loss:1.1637883186340332\n",
      "Batch:20 Loss:1.3740283250808716\n",
      "Batch:21 Loss:0.9790971279144287\n",
      "Batch:22 Loss:1.2465611696243286\n",
      "Batch:23 Loss:1.2023109197616577\n",
      "Batch:24 Loss:1.1767678260803223\n",
      "Batch:25 Loss:1.150943398475647\n",
      "Batch:26 Loss:1.2040135860443115\n",
      "Batch:27 Loss:0.9652894139289856\n",
      "Batch:28 Loss:1.1256970167160034\n",
      "Batch:29 Loss:1.137367606163025\n",
      "Batch:30 Loss:1.2164032459259033\n",
      "Batch:31 Loss:1.1504130363464355\n",
      "Batch:32 Loss:1.139521598815918\n",
      "Batch:33 Loss:1.0697474479675293\n",
      "Batch:34 Loss:1.114113450050354\n",
      "Batch:35 Loss:1.0675591230392456\n",
      "Batch:36 Loss:1.208473801612854\n",
      "Batch:37 Loss:1.1083033084869385\n",
      "Batch:38 Loss:1.196732759475708\n",
      "Batch:39 Loss:1.1239235401153564\n",
      "Batch:40 Loss:1.189170002937317\n",
      "Batch:41 Loss:1.0691758394241333\n",
      "Batch:42 Loss:1.0270609855651855\n",
      "Batch:43 Loss:1.1213505268096924\n",
      "Batch:44 Loss:1.1105396747589111\n",
      "Batch:45 Loss:0.9604288339614868\n",
      "Batch:46 Loss:1.196224331855774\n",
      "Batch:47 Loss:1.0406779050827026\n",
      "Batch:48 Loss:0.9296228885650635\n",
      "Batch:49 Loss:1.1598365306854248\n",
      "Batch:50 Loss:1.0902327299118042\n",
      "Batch:51 Loss:1.2425282001495361\n",
      "Batch:52 Loss:0.9404985904693604\n",
      "Batch:53 Loss:1.1259698867797852\n",
      "Batch:54 Loss:1.1716198921203613\n",
      "Batch:55 Loss:1.0155200958251953\n",
      "Batch:56 Loss:1.0274816751480103\n",
      "Batch:57 Loss:1.0555938482284546\n",
      "Batch:58 Loss:1.0897316932678223\n",
      "Batch:59 Loss:1.1640615463256836\n",
      "Batch:60 Loss:1.1135754585266113\n",
      "Batch:61 Loss:1.036780595779419\n",
      "Batch:62 Loss:1.1415328979492188\n",
      "Batch:63 Loss:1.1108546257019043\n",
      "Batch:64 Loss:0.9595432877540588\n",
      "Batch:65 Loss:1.1945972442626953\n",
      "Batch:66 Loss:0.9327853918075562\n",
      "Batch:67 Loss:1.1348698139190674\n",
      "Batch:68 Loss:1.0822315216064453\n",
      "Batch:69 Loss:1.1490705013275146\n",
      "Batch:70 Loss:0.8870416283607483\n",
      "Batch:71 Loss:1.1126147508621216\n",
      "Batch:72 Loss:1.0941503047943115\n",
      "Batch:73 Loss:1.1246410608291626\n",
      "Batch:74 Loss:1.136487364768982\n",
      "Batch:75 Loss:1.0701268911361694\n",
      "Batch:76 Loss:0.9245036840438843\n",
      "Batch:77 Loss:1.0998185873031616\n",
      "Batch:78 Loss:1.0843353271484375\n",
      "MSE on cv_3_df:1.0623537679907673\n",
      "----------------\n",
      "Test on cv_4_df\n",
      "Starting training porcess...\n",
      "Batch:0 Loss:1.2046157121658325\n",
      "Batch:1 Loss:1.285876750946045\n",
      "Batch:2 Loss:1.1112247705459595\n",
      "Batch:3 Loss:0.989171028137207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:4 Loss:0.9505516886711121\n",
      "Batch:5 Loss:1.237420916557312\n",
      "Batch:6 Loss:1.1586445569992065\n",
      "Batch:7 Loss:1.4052116870880127\n",
      "Batch:8 Loss:1.0392869710922241\n",
      "Batch:9 Loss:1.255163311958313\n",
      "Batch:10 Loss:1.0966659784317017\n",
      "Batch:11 Loss:1.1131491661071777\n",
      "Batch:12 Loss:1.1196949481964111\n",
      "Batch:13 Loss:0.9964392185211182\n",
      "Batch:14 Loss:0.9976995587348938\n",
      "Batch:15 Loss:1.0105879306793213\n",
      "Batch:16 Loss:1.097186803817749\n",
      "Batch:17 Loss:1.1171531677246094\n",
      "Batch:18 Loss:1.1770986318588257\n",
      "Batch:19 Loss:1.1074777841567993\n",
      "Batch:20 Loss:1.2725296020507812\n",
      "Batch:21 Loss:0.9205043911933899\n",
      "Batch:22 Loss:1.1705653667449951\n",
      "Batch:23 Loss:1.1528295278549194\n",
      "Batch:24 Loss:1.103266954421997\n",
      "Batch:25 Loss:1.0771379470825195\n",
      "Batch:26 Loss:1.130826711654663\n",
      "Batch:27 Loss:0.9080814719200134\n",
      "Batch:28 Loss:1.0639129877090454\n",
      "Batch:29 Loss:1.0799121856689453\n",
      "Batch:30 Loss:1.1695717573165894\n"
     ]
    }
   ],
   "source": [
    "mse_lst = []\n",
    "\n",
    "for test_idx in range(5):\n",
    "    print('----------------')\n",
    "    print('Test on cv_{0}_df'.format(test_idx+1))\n",
    "    train_idx_lst = [i for i in range(5) if i!=test_idx]\n",
    "    # 训练过程\n",
    "    train_df_lst = []\n",
    "    for train_idx in train_idx_lst:\n",
    "        df = cv_df_lst[train_idx]\n",
    "        train_df_lst.append(df[df['type']=='test'])\n",
    "    train_df = pd.concat(train_df_lst)\n",
    "    train_dataset = MLManDataSet(train_df)\n",
    "    train_dataloader = DataLoader(train_dataset,batch_size=BATCH_SIZE)\n",
    "    \n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    print('Starting training porcess...')\n",
    "    for num,(uid_batch,iid_batch,usr_feature,item_feature,true_y) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        pred_y = model(uid_batch,iid_batch,usr_feature,item_feature)\n",
    "        true_y = true_y.to(torch.float).to(DEVICE)\n",
    "        loss = criterion(pred_y,true_y)\n",
    "        loss.requires_grad_(True)\n",
    "        loss.backward()\n",
    "        print('Batch:{0} Loss:{1}'.format(num,loss))\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 测试过程\n",
    "    model.eval()\n",
    "    df = cv_df_lst[test_idx]\n",
    "    test_df = df[df['type']=='test']\n",
    "\n",
    "    test_dataset = MLManDataSet(test_df)\n",
    "    test_dataloader = DataLoader(test_dataset,batch_size=BATCH_SIZE)\n",
    "    \n",
    "    temp_mse_lst = []\n",
    "    # 分batch进行MSE计算 最后平均\n",
    "    for num,(test_uid_batch,test_iid_batch,test_usr_feature,test_item_feature,test_true_y) in enumerate(train_dataloader):\n",
    "    \n",
    "        test_pred_y = model(test_uid_batch,test_iid_batch,test_usr_feature,test_item_feature)\n",
    "        test_pred_y = test_pred_y.cpu().detach().numpy()\n",
    "        \n",
    "        mse_batch = mean_squared_error(test_true_y,test_pred_y)\n",
    "        temp_mse_lst.append(mse_batch)\n",
    "        \n",
    "    mse = np.average(temp_mse_lst)\n",
    "    mse_lst.append(mse)\n",
    "    print('MSE on cv_{0}_df:{1}'.format(test_idx+1,mse))\n",
    "print('Average MSE:{0}'.format(np.average(mse_lst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比lgbRegression\n",
    "\n",
    "```\n",
    "----------------\n",
    "Test on cv_1_df\n",
    "MSE on cv_5_df:0.9916941295553173\n",
    "----------------\n",
    "Test on cv_2_df\n",
    "MSE on cv_5_df:0.9696588575493511\n",
    "----------------\n",
    "Test on cv_3_df\n",
    "MSE on cv_5_df:0.9576872585148317\n",
    "----------------\n",
    "Test on cv_4_df\n",
    "MSE on cv_5_df:0.9672447937961466\n",
    "----------------\n",
    "Test on cv_5_df\n",
    "MSE on cv_5_df:0.97248790766502\n",
    "Average MSE:0.9717545894161332\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
