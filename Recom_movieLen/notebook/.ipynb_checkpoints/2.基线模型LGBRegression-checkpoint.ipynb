{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.055135Z",
     "start_time": "2020-10-13T13:20:45.452714Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.061262Z",
     "start_time": "2020-10-13T13:20:46.057096Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.133471Z",
     "start_time": "2020-10-13T13:20:46.063166Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle('../data/processed/data_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.141007Z",
     "start_time": "2020-10-13T13:20:46.135964Z"
    }
   },
   "outputs": [],
   "source": [
    "usr_df = pd.read_pickle('../data/processed/usr_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.153192Z",
     "start_time": "2020-10-13T13:20:46.142852Z"
    }
   },
   "outputs": [],
   "source": [
    "item_df = pd.read_pickle('../data/processed/item_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.抽取用户和物品各自特征并进行处理\n",
    "\n",
    "针对独立类别特征进行分桶(categories)\n",
    "\n",
    "相关方法参见:https://www.kaggle.com/shahules/an-overview-of-encoding-techniques\n",
    "\n",
    "针对数值型特征(年龄)进行scale之后normalization\n",
    "\n",
    "即先将所有值减去最小值后除以最大最小值之差,在此基础上减去特征的均值并除以标准差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1处理用户特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.160320Z",
     "start_time": "2020-10-13T13:20:46.155260Z"
    }
   },
   "outputs": [],
   "source": [
    "occupation_lst = [i.strip() for i in open('../data/raw_data/u.occupation','r',encoding='utf-8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.226160Z",
     "start_time": "2020-10-13T13:20:46.163066Z"
    }
   },
   "outputs": [],
   "source": [
    "usr_feature_df = pd.DataFrame()\n",
    "usr_feature_df['usr_id'] = usr_df['usr_id'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.237525Z",
     "start_time": "2020-10-13T13:20:46.229530Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_and_norm(df,colname):\n",
    "    '''连续数值型特征归一化和正规化\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    max_ = max(df[colname])\n",
    "    min_ = min(df[colname])\n",
    "    df[colname] = df[colname].apply(lambda x:(x-min_)/(max_-min_))\n",
    "\n",
    "    mean_scaled = np.mean(df[colname])\n",
    "    std_scaled = np.std(df[colname])\n",
    "\n",
    "    df[colname] = df[colname].apply(lambda x:(x-mean_scaled)/std_scaled)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.249678Z",
     "start_time": "2020-10-13T13:20:46.239955Z"
    }
   },
   "outputs": [],
   "source": [
    "def target_encoding(df,colname,cate_lst=None):\n",
    "    '''\n",
    "    此处使用target encoding方法 将类别在总体占比作为其特征值(cate_lst基本无用)\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    col_value = df[colname].tolist()\n",
    "    col_counter = Counter(col_value)\n",
    "\n",
    "    col_frac = {k:col_counter[k]/sum(col_counter.values()) for k in col_counter}\n",
    "\n",
    "    df[colname] = df[colname].apply(lambda x:col_frac[x])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.265916Z",
     "start_time": "2020-10-13T13:20:46.251702Z"
    }
   },
   "outputs": [],
   "source": [
    "def onehot_encoding(df,colname,cate_lst=None):\n",
    "    '''离散型特征分桶类别化(categorization)\n",
    "    cate_lst为对应类别的既有顺序 默认为None 如果有的话 类别化时参照lst中的顺序进行编码\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    col_value = df[colname].tolist()\n",
    "    if cate_lst is None:\n",
    "        cate_lst = list(set(col_value))\n",
    "    df[colname] = df[colname].apply(lambda x:cate_lst.index(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.280395Z",
     "start_time": "2020-10-13T13:20:46.268053Z"
    }
   },
   "outputs": [],
   "source": [
    "usr_feature_df['age'] = [int(i) for i in usr_df['age']]\n",
    "usr_feature_df['gender'] = usr_df['gender']\n",
    "usr_feature_df['occupation'] = usr_df['occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.298954Z",
     "start_time": "2020-10-13T13:20:46.282558Z"
    }
   },
   "outputs": [],
   "source": [
    "usr_feature_df = scale_and_norm(usr_feature_df,'age')\n",
    "usr_feature_df = target_encoding(usr_feature_df,'gender')\n",
    "usr_feature_df = target_encoding(usr_feature_df,'occupation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 处理物品特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.304959Z",
     "start_time": "2020-10-13T13:20:46.301216Z"
    }
   },
   "outputs": [],
   "source": [
    "movie_type = [i.strip().split('|')[0] for i in open('../data/raw_data/u.genre').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.315400Z",
     "start_time": "2020-10-13T13:20:46.306810Z"
    }
   },
   "outputs": [],
   "source": [
    "movie_type = movie_type[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.331900Z",
     "start_time": "2020-10-13T13:20:46.317397Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_feature_df = pd.DataFrame()\n",
    "item_feature_df['item_id'] = item_df['item_id']\n",
    "item_feature_df['movie_title'] = item_df['movie_title'].apply(lambda x:x.split('(')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.344459Z",
     "start_time": "2020-10-13T13:20:46.334150Z"
    }
   },
   "outputs": [],
   "source": [
    "item_feature_df['release_year'] = item_df['release_date'].apply(lambda x:x.split('-')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.358125Z",
     "start_time": "2020-10-13T13:20:46.346726Z"
    }
   },
   "outputs": [],
   "source": [
    "item_feature_df = target_encoding(item_feature_df,'release_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.368851Z",
     "start_time": "2020-10-13T13:20:46.360356Z"
    }
   },
   "outputs": [],
   "source": [
    "item_type_matrix = item_df[movie_type].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.387312Z",
     "start_time": "2020-10-13T13:20:46.370836Z"
    }
   },
   "outputs": [],
   "source": [
    "item_type_matrix = item_type_matrix.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.400787Z",
     "start_time": "2020-10-13T13:20:46.389681Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_feature_df['type_feature'] = [i for i in item_type_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.411278Z",
     "start_time": "2020-10-13T13:20:46.402944Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# movie_title_text = item_feature_df['item_id'].tolist()\n",
    "\n",
    "# tfidf_obj = TfidfVectorizer(max_features=50)\n",
    "\n",
    "# item_tfidf_feature = tfidf_obj.fit_transform(movie_title_text)\n",
    "\n",
    "# item_tfidf_feature = item_tfidf_feature.toarray()\n",
    "\n",
    "# item_feature_df['tfidf_feature'] = [i for i in item_tfidf_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.427838Z",
     "start_time": "2020-10-13T13:20:46.413696Z"
    }
   },
   "outputs": [],
   "source": [
    "usr_feautre = usr_feature_df[['age','gender','occupation']].copy().to_numpy()\n",
    "usr_feature_df = pd.DataFrame()\n",
    "usr_feature_df['usr_id'] = usr_df['usr_id'].copy()\n",
    "usr_feature_df['features'] = [i for i in usr_feautre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.507972Z",
     "start_time": "2020-10-13T13:20:46.431771Z"
    }
   },
   "outputs": [],
   "source": [
    "item_feature = []\n",
    "for num,_ in enumerate(item_feature_df.itertuples()):\n",
    "    year = item_feature_df.loc[num,'release_year']\n",
    "    type_feature = item_feature_df.loc[num,'type_feature']\n",
    "    feature = np.hstack([np.array([year]),type_feature])\n",
    "    item_feature.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.516492Z",
     "start_time": "2020-10-13T13:20:46.509952Z"
    }
   },
   "outputs": [],
   "source": [
    "item_feature_df = pd.DataFrame()\n",
    "item_feature_df['item_id'] = item_df['item_id'].copy()\n",
    "item_feature_df['features'] = [i for i in item_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.527437Z",
     "start_time": "2020-10-13T13:20:46.518318Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_Xy(df,\n",
    "           usr_feautre_df=usr_feature_df,\n",
    "           item_feature_df=item_feature_df):\n",
    "    '''给定数据df 按照顺序输出特征和对应标签\n",
    "    拼接之后的数据\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    uid_lst = [int(i) for i in df['usr_id'].tolist()]\n",
    "    iid_lst = [int(i) for i in df['item_id'].tolist()]\n",
    "\n",
    "    u_feature = [usr_feature_df.loc[i-1,'features'] for i in uid_lst]\n",
    "\n",
    "    u_feature = np.array(u_feature)\n",
    "\n",
    "    i_feature = [item_feature_df.loc[i-1,'features'] for i in iid_lst]\n",
    "\n",
    "    i_feature = np.array(i_feature)\n",
    "\n",
    "    X = np.hstack([u_feature,i_feature])\n",
    "    y = [int(i) for i in df['rating'].tolist()]\n",
    "    y = np.array(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.554336Z",
     "start_time": "2020-10-13T13:20:46.529399Z"
    }
   },
   "outputs": [],
   "source": [
    "item_feature_df.to_pickle('../data/processed/item_feature_df.pkl')\n",
    "usr_feature_df.to_pickle('../data/processed/usr_feature_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.基线模型\n",
    "\n",
    "评价指标为RMSE,MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1作为回归任务来做\n",
    "\n",
    "每个用户和物品的交互评分作为一个标注,训练回归模型.测试集上对应进行预测即可.\n",
    "\n",
    "模型输入:用户特征和物品特征拼接,对应标注为rating分数.\n",
    "模型输出:rating分数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.894668Z",
     "start_time": "2020-10-13T13:20:46.556361Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:46.927572Z",
     "start_time": "2020-10-13T13:20:46.896269Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 五折交叉验证\n",
    "\n",
    "四折的训练集数据训练，另外一折数据的测试集做测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:47.148558Z",
     "start_time": "2020-10-13T13:20:46.929850Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_df_lst = []\n",
    "for i in range(5):\n",
    "    df_fname = '../data/processed/cv_{0}_df.pkl'.format(i+1)\n",
    "    df = pd.read_pickle(df_fname)\n",
    "    cv_df_lst.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:47.154262Z",
     "start_time": "2020-10-13T13:20:47.150522Z"
    }
   },
   "outputs": [],
   "source": [
    "best_param = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'regression',\n",
    "          'nthread': 8, # Updated from nthread\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:20:47.165303Z",
     "start_time": "2020-10-13T13:20:47.155964Z"
    }
   },
   "outputs": [],
   "source": [
    "model = lightgbm.LGBMRegressor(**best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T13:21:07.784787Z",
     "start_time": "2020-10-13T13:20:47.167341Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Test on cv_1_df\n",
      "MSE on cv_5_df:1.1294285794135475\n",
      "----------------\n",
      "Test on cv_2_df\n",
      "MSE on cv_5_df:1.0860408137803688\n",
      "----------------\n",
      "Test on cv_3_df\n",
      "MSE on cv_5_df:1.0485731813061572\n",
      "----------------\n",
      "Test on cv_4_df\n",
      "MSE on cv_5_df:1.0336211280458831\n",
      "----------------\n",
      "Test on cv_5_df\n",
      "MSE on cv_5_df:1.0389689167348395\n",
      "Average MSE:1.0673265238561593\n"
     ]
    }
   ],
   "source": [
    "mse_lst = []\n",
    "for test_idx in range(5):\n",
    "    print('----------------')\n",
    "    print('Test on cv_{0}_df'.format(test_idx+1))\n",
    "    train_idx_lst = [i for i in range(5) if i!=test_idx]\n",
    "    # 训练过程 其余四份test集合作为训练集 当前作为测试\n",
    "    for train_idx in train_idx_lst:\n",
    "        df = cv_df_lst[train_idx]\n",
    "        train_df = df[df['type']=='test']\n",
    "        train_X,train_y = get_Xy(train_df)\n",
    "        model.fit(train_X,train_y)\n",
    "    # 测试过程\n",
    "    df = cv_df_lst[test_idx]\n",
    "    test_df = df[df['type']=='test']\n",
    "    test_X,test_true_y = get_Xy(test_df)\n",
    "    test_pred_y = model.predict(test_X)\n",
    "    mse = mean_squared_error(test_true_y,test_pred_y)\n",
    "    mse_lst.append(mse)\n",
    "    print('MSE on cv_{0}_df:{1}'.format(i+1,mse))\n",
    "print('Average MSE:{0}'.format(np.average(mse_lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
